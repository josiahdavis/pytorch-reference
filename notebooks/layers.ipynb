{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Reference Layers\n",
    "\n",
    "A reference made for personal use on common layers in PyTorch. Not meant to be comprehensive. \n",
    "\n",
    "Currently:\n",
    "\n",
    "1. Linear\n",
    "2. Embeddings\n",
    "3. Dropout\n",
    "4. Transformers\n",
    "\n",
    "Created by Josiah Davis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform Linux-4.15.0-1060-aws-x86_64-with-debian-buster-sid\n",
      "Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) \n",
      "[GCC 7.2.0]\n",
      "PyTorch 1.3.1\n"
     ]
    }
   ],
   "source": [
    "import platform; print(\"Platform\", platform.platform())\n",
    "import sys; print(\"Python\", sys.version)\n",
    "import torch; print(\"PyTorch\", torch.__version__)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear\n",
    "\n",
    "Handles the core matrix multiply of the form $y = xA^T + b$, where $x$ is the data, $A$ is the learned weight parameter and $b$ is the bias term.\n",
    "\n",
    "### [`nn.Linear(in_features, out_features)`](https://pytorch.org/docs/stable/nn.html#linear)\n",
    "\n",
    "- **Input**: 2D of the form [observations, input_features] (e.g., [10, 8]).\n",
    "- **Arguments**: First arg is number of columns in the input called `in_features` (e.g., 8), second arg is number of columns in output called `out_features` (e.g., 16).\n",
    "- **Output**: 2D of the form [observations, output_features] (e.g., [10, 16])\n",
    "- **Stores**: Layer stores two parameters, the bias with shape=`out_features` and weight with shape=[`out_features`, `in_features`]). The weight matrix is tranposed before being multiplied by the input matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 16])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(10, 8) # [observations, in_features]\n",
    "lin = nn.Linear(8, 16)\n",
    "y = lin(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.bias.shape # [out_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.weight.shape # [out_features, in_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values are initialized by default with uniform distribution about $\\sqrt{\\frac{1}{{in\\_features}}}$ ([source code](https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear)). \n",
    "\n",
    "For example, we had 8 input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3535533905932738\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.sqrt(1/8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.34973994 -0.2796788  -0.20961763 -0.13955648 -0.06949533  0.00056583\n",
      "  0.07062698  0.14068814  0.21074928  0.28081045  0.3508716 ]\n"
     ]
    }
   ],
   "source": [
    "vals = lin.weight.detach().numpy()\n",
    "counts, cutoffs = np.histogram(vals)\n",
    "print(cutoffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization could be changed as desired. For example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLin(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CustomLin, self).__init__()\n",
    "        self.lin1 = nn.Linear(8, 16)\n",
    "        self.lin2 = nn.Linear(16, 6)\n",
    "        self._init_layers()\n",
    "        \n",
    "    def _init_layers(self):\n",
    "        init_1 = np.sqrt(6) / np.sqrt(8 + 16)\n",
    "        self.lin1.weight.data.uniform_(-init_1, init_1)\n",
    "        self.lin1.bias.data.zero_()\n",
    "        \n",
    "        self.lin2.weight.data.normal_(mean=0, std=np.sqrt(6 / 16))\n",
    "        self.lin2.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin2(self.lin1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = CustomLin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[-0.49987888 -0.40455016 -0.30922145 -0.21389274 -0.11856403 -0.02323532\n",
      "  0.07209339  0.1674221   0.2627508   0.35807952  0.45340824]\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(6) / np.sqrt(8 + 16))\n",
    "counts, cutoffs = np.histogram(cl.lin1.weight.detach().numpy())\n",
    "print(cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6123724356957945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.071864285, 0.605536)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.sqrt(6 / 16))\n",
    "wts = cl.lin2.weight.detach().numpy()\n",
    "wts.mean(), wts.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For learning about some of the history and development of weight initialization, consult:\n",
    "- [Understanding the difficulty of training deep feedforward neural networks (2010)](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) by Xavier Glorot and Yoshua Bengio\n",
    "- [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification (2015)](https://arxiv.org/pdf/1502.01852.pdf) by Kaiming He, Xiangyu Zhang, Shaoqing Ren,  Jian Sun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embeddings\n",
    "\n",
    "### [`nn.Embedding(num_embeddings, embedding_dim)`](https://pytorch.org/docs/stable/nn.html#embedding)\n",
    "\n",
    "Simple lookup of any categorical variable (often NLP vocabulary) mapping to dense floating point representations.\n",
    "\n",
    "#### Shape\n",
    "\n",
    "- Input: Could be 1D or 2D depending on the application.\n",
    "- Output: If the input is 1D, output will be 2D, if the input is 2D, output will be 2D.\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "- **num_embeddings** (int) – how large is the vocab in dictionary or how many categories are there? (e.g., 25)\n",
    "- **embedding_dim** (int) – the number of features (e.g., 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D input example (e.g., a single column in tablular data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([3])\n",
      "output shape: torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([15, 20, 7])\n",
    "print(f'input shape: {x.shape}')\n",
    "emb = nn.Embedding(num_embeddings=25, embedding_dim=5)\n",
    "y = emb(x)\n",
    "print(f'output shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D input example (e.g., text for language modelling with sequence on the rows and \"text chunk\" on the columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([2, 3])\n",
      "output shape: torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[15, 20, 7],[23, 10, 6]])\n",
    "print(f'input shape: {x.shape}')\n",
    "emb = nn.Embedding(num_embeddings=25, embedding_dim=5)\n",
    "y = emb(x)\n",
    "print(f'output shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.9857,  0.6738, -1.3308,  0.6104,  0.4368],\n",
       "        [ 1.1923,  0.2208,  1.3420,  0.2724, -0.3383],\n",
       "        [ 1.1209, -1.0355, -1.0666, -0.6748,  1.8354],\n",
       "        [ 0.1832, -0.7247,  0.3047,  0.5994, -0.1622],\n",
       "        [ 1.2293, -0.9944,  0.0545,  0.2088,  0.8442],\n",
       "        [-0.2275,  1.0348, -0.1023, -1.4188, -0.1926],\n",
       "        [-1.1492, -1.2622, -0.7481,  0.8993,  1.0637],\n",
       "        [-0.1893, -0.4812, -0.8839, -0.3168,  1.1439],\n",
       "        [ 0.9222,  0.3558, -0.7736,  0.4515, -1.9237],\n",
       "        [ 0.2411,  1.3968, -1.2450, -0.0553, -0.5514],\n",
       "        [-1.0053,  0.9058,  0.9180,  0.4477,  0.0537],\n",
       "        [-0.2617,  0.6926, -0.5694, -0.6246,  2.1864],\n",
       "        [ 0.4094,  0.1337, -0.5880, -0.7409,  0.5854],\n",
       "        [-1.1285, -0.4147, -0.2701, -0.1995,  0.0327],\n",
       "        [ 1.5854, -0.3498, -0.4903, -0.0224,  0.9896],\n",
       "        [-0.8889,  0.2809, -2.2613,  0.2511,  0.6522],\n",
       "        [-0.5991,  1.0116,  0.0659, -0.5952,  1.8904],\n",
       "        [ 1.0922,  0.3825,  0.2867,  0.6715,  0.1081],\n",
       "        [-1.6416, -0.3541,  0.2380,  0.5315, -0.0864],\n",
       "        [ 0.2316, -0.6041, -0.3396, -0.7598, -0.2170],\n",
       "        [ 0.0629,  1.6860,  0.3800, -1.0374, -0.2858],\n",
       "        [ 0.8800,  0.8275, -0.2410, -0.3459, -0.9978],\n",
       "        [-1.8755, -0.3097,  0.0445, -0.1144, -0.3293],\n",
       "        [-0.3840, -0.3846, -0.9646,  1.4485,  0.3196],\n",
       "        [ 0.7593,  1.8614, -0.4110, -0.0248, -1.7999]], requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dropout\n",
    "\n",
    "### [`nn.Dropout(p)`](https://pytorch.org/docs/master/nn.html#dropout)\n",
    "\n",
    "Randomly zero out elements from input matrix for regularization. Doesn't work when `model.eval()` is set. Also re-normalizes the output values not zero'd out by $\\frac{1}{1-p}$.\n",
    "\n",
    "**Input:** Can be any shape\n",
    "\n",
    "**Output:** Same shape as input\n",
    "\n",
    "**See Also:** `nn.Dropout2d` and `nn.Dropout3d` for zero-ing entire channels at a time.\n",
    "\n",
    "**Paper**: Improving neural networks by preventing co-adaptation of feature detectors (2012) ([arxiv](https://arxiv.org/pdf/1207.0580.pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([2, 4])\n",
      "output shape: torch.Size([2, 4])\n",
      "output:\n",
      "tensor([[ 0.0000, -0.0000,  0.0000, -0.0000],\n",
      "        [-2.6023, -0.2766,  0.0000, -0.4595]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 4)\n",
    "print(f'input shape: {x.shape}')\n",
    "do = nn.Dropout(p=0.6)\n",
    "y = do(x)\n",
    "print(f'output shape: {y.shape}')\n",
    "print(f'output:\\n{y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout is only activated once the training mode is turned on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DOModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.do = nn.Dropout(0.6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.do(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1225,  0.1723, -2.2045,  1.0320],\n",
       "        [-0.6691, -0.3356, -1.1725,  0.1653]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running with `model.train()`. This will give you a different output each time you call it (unless you set a seed). \n",
    "\n",
    "Incidentally, this is the key to monte carlo dropout, a technique for uncertainty estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      "tensor([[ 0.0000,  0.4308, -5.5112,  2.5801],\n",
      "        [-0.0000, -0.8390, -0.0000,  0.4134]])\n"
     ]
    }
   ],
   "source": [
    "model = DOModel()\n",
    "model.train()\n",
    "y = model(x)\n",
    "print(f'output:\\n{y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running again with `model.eval()`. This will give you the same output no matter how many times you call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      "tensor([[ 0.1225,  0.1723, -2.2045,  1.0320],\n",
      "        [-0.6691, -0.3356, -1.1725,  0.1653]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y = model(x)\n",
    "print(f'output:\\n{y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transformers\n",
    "\n",
    "### [`nn.TransformerEncoderLayer(d_model, nhead)`](https://pytorch.org/docs/master/nn.html?highlight=transformerencoderlayer#torch.nn.TransformerEncoderLayer)\n",
    "\n",
    "Transformer operations are defined in \"Attention is all you need (2017).\" Differece between this and the Decoder layer is that the Encoder only attends to itself (Key/Value/Query is the source langage). Whereas in Decoder layer there is an attention over the memory (i.e., encoding of the input sequence) as well as the self-attention over the target sequence.\n",
    "\n",
    "**Input**: A 3D input of the structure [sequence length, batch size, hidden features].\n",
    "\n",
    "**Output**: Same structure as input.\n",
    "\n",
    "**Operation**: Key, Value, and Query are all the source sentence (only self-attention). See [source code](https://pytorch.org/docs/master/_modules/torch/nn/modules/transformer.html#TransformerEncoderLayer)\n",
    "\n",
    "```\n",
    "src2 = self.self_attn(src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask)[0]\n",
    "src = src + self.dropout1(src2)\n",
    "src = self.norm1(src)\n",
    "src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "src = src + self.dropout2(src2)\n",
    "src = self.norm2(src)\n",
    "return src\n",
    "```\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- **d_model** – the number of expected features in the input (required).\n",
    "- **nhead** – the number of heads in the multiheadattention models (required).\n",
    "- **dim_feedforward** – the dimension of the feedforward network model (default=2048).\n",
    "- **dropout** – the dropout value (default=0.1).\n",
    "- **activation** – the activation function of intermediate layer, relu or gelu (default=relu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([10, 32, 512])\n",
      "output shape: torch.Size([10, 32, 512])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(10, 32, 512)\n",
    "print(f'input shape: {x.shape}')\n",
    "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "y = encoder_layer(x)\n",
    "print(f'output shape: {y.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
