{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Reference Layers\n",
    "\n",
    "A reference made for personal use on common layers in PyTorch. Not meant to be comprehensive. \n",
    "\n",
    "Currently:\n",
    "\n",
    "1. Linear\n",
    "2. Embeddings\n",
    "3. Dropout\n",
    "4. Transformers\n",
    "\n",
    "Created by Josiah Davis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform Linux-4.15.0-1060-aws-x86_64-with-debian-buster-sid\n",
      "Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) \n",
      "[GCC 7.2.0]\n",
      "PyTorch 1.3.1\n"
     ]
    }
   ],
   "source": [
    "import platform; print(\"Platform\", platform.platform())\n",
    "import sys; print(\"Python\", sys.version)\n",
    "import torch; print(\"PyTorch\", torch.__version__)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear\n",
    "\n",
    "Handles the core matrix multiply of the form $y = xA^T + b$, where $x$ is the data, $A$ is the learned weight parameter and $b$ is the bias term.\n",
    "\n",
    "### [`nn.Linear(in_features, out_features)`](https://pytorch.org/docs/stable/nn.html#linear)\n",
    "\n",
    "- **Input**: 2D of the form [observations, input_features] (e.g., [10, 8]).\n",
    "- **Arguments**: First arg is number of columns in the input called `in_features` (e.g., 8), second arg is number of columns in output called `out_features` (e.g., 16).\n",
    "- **Output**: 2D of the form [observations, output_features] (e.g., [10, 16])\n",
    "- **Stores**: Layer stores two parameters, the bias with shape=`out_features` and weight with shape=[`out_features`, `in_features`]). The weight matrix is tranposed before being multiplied by the input matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 16])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(10, 8) # [observations, in_features]\n",
    "lin = nn.Linear(8, 16)\n",
    "y = lin(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.bias.shape # [out_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.weight.shape # [out_features, in_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values are initialized by default with uniform distribution about $\\sqrt{\\frac{1}{{in\\_features}}}$ ([source code](https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear)). \n",
    "\n",
    "For example, we had 8 input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3535533905932738\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.sqrt(1/8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35226142 -0.28203014 -0.21179885 -0.14156754 -0.07133625 -0.00110497\n",
      "  0.06912632  0.13935761  0.20958892  0.2798202   0.3500515 ]\n"
     ]
    }
   ],
   "source": [
    "vals = lin.weight.detach().numpy()\n",
    "counts, cutoffs = np.histogram(vals)\n",
    "print(cutoffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization could be changed as desired. For example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLin(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CustomLin, self).__init__()\n",
    "        self.lin1 = nn.Linear(8, 16)\n",
    "        self.lin2 = nn.Linear(16, 6)\n",
    "        self._init_layers()\n",
    "        \n",
    "    def _init_layers(self):\n",
    "        init_1 = np.sqrt(6) / np.sqrt(8 + 16)\n",
    "        self.lin1.weight.data.uniform_(-init_1, init_1)\n",
    "        self.lin1.bias.data.zero_()\n",
    "        \n",
    "        self.lin2.weight.data.normal_(mean=0, std=np.sqrt(6 / 16))\n",
    "        self.lin2.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin2(self.lin1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = CustomLin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[-0.49063146 -0.39208794 -0.2935444  -0.19500087 -0.09645734  0.00208619\n",
      "  0.10062972  0.19917326  0.2977168   0.39626032  0.49480385]\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(6) / np.sqrt(8 + 16))\n",
    "counts, cutoffs = np.histogram(cl.lin1.weight.detach().numpy())\n",
    "print(cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6123724356957945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.05647954, 0.62495434)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.sqrt(6 / 16))\n",
    "wts = cl.lin2.weight.detach().numpy()\n",
    "wts.mean(), wts.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For learning about some of the history and development of weight initialization, consult:\n",
    "- [Understanding the difficulty of training deep feedforward neural networks (2010)](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) by Xavier Glorot and Yoshua Bengio\n",
    "- [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification (2015)](https://arxiv.org/pdf/1502.01852.pdf) by Kaiming He, Xiangyu Zhang, Shaoqing Ren,  Jian Sun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embeddings\n",
    "\n",
    "### [`nn.Embedding(num_embeddings, embedding_dim)`](https://pytorch.org/docs/stable/nn.html#embedding)\n",
    "\n",
    "Simple lookup of any categorical variable (often NLP vocabulary) mapping to dense floating point representations.\n",
    "\n",
    "#### Shape\n",
    "\n",
    "- Input: Could be 1D or 2D depending on the application.\n",
    "- Output: If the input is 1D, output will be 2D, if the input is 2D, output will be 2D.\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "- **num_embeddings** (int) – how large is the vocab in dictionary or how many categories are there? (e.g., 25)\n",
    "- **embedding_dim** (int) – the number of features (e.g., 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D input example (e.g., a single column in tablular data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([3])\n",
      "output shape: torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([15, 20, 7])\n",
    "print(f'input shape: {x.shape}')\n",
    "emb = nn.Embedding(num_embeddings=25, embedding_dim=5)\n",
    "y = emb(x)\n",
    "print(f'output shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D input example (e.g., text for language modelling with sequence on the rows and \"text chunk\" on the columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([2, 3])\n",
      "output shape: torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[15, 20, 7],[23, 10, 6]])\n",
    "print(f'input shape: {x.shape}')\n",
    "emb = nn.Embedding(num_embeddings=25, embedding_dim=5)\n",
    "y = emb(x)\n",
    "print(f'output shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dropout\n",
    "\n",
    "### [`nn.Dropout(p)`](https://pytorch.org/docs/master/nn.html#dropout)\n",
    "\n",
    "Randomly zero out elements from input matrix for regularization. Doesn't work when `model.eval()` is set. Also re-normalizes the output values not zero'd out by $\\frac{1}{1-p}$.\n",
    "\n",
    "**Input:** Can be any shape\n",
    "\n",
    "**Output:** Same shape as input\n",
    "\n",
    "**See Also:** `nn.Dropout2d` and `nn.Dropout3d` for zero-ing entire channels at a time.\n",
    "\n",
    "**Paper**: Improving neural networks by preventing co-adaptation of feature detectors (2012) ([arxiv](https://arxiv.org/pdf/1207.0580.pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([2, 4])\n",
      "output shape: torch.Size([2, 4])\n",
      "output:\n",
      "tensor([[-1.2521, -1.9967, -1.2923, -0.0000],\n",
      "        [ 0.2889,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 4)\n",
    "print(f'input shape: {x.shape}')\n",
    "do = nn.Dropout(p=0.6)\n",
    "y = do(x)\n",
    "print(f'output shape: {y.shape}')\n",
    "print(f'output:\\n{y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout is only activated once the training mode is turned on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DOModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.do = nn.Dropout(0.6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.do(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8707,  0.3161, -0.6182,  0.2612],\n",
       "        [-0.4746,  0.3197,  0.9153,  1.8096]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running with `model.train()`. This will give you a different output each time you call it (unless you set a seed). \n",
    "\n",
    "Incidentally, this is the key to monte carlo dropout, a technique for uncertainty estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      "tensor([[-0.0000,  0.7902, -0.0000,  0.0000],\n",
      "        [-1.1865,  0.7994,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "model = DOModel()\n",
    "model.train()\n",
    "y = model(x)\n",
    "print(f'output:\\n{y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running again with `model.eval()`. This will give you the same output no matter how many times you call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      "tensor([[-0.8707,  0.3161, -0.6182,  0.2612],\n",
      "        [-0.4746,  0.3197,  0.9153,  1.8096]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y = model(x)\n",
    "print(f'output:\\n{y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transformers\n",
    "\n",
    "### [`nn.TransformerEncoderLayer(d_model, nhead)`](https://pytorch.org/docs/master/nn.html?highlight=transformerencoderlayer#torch.nn.TransformerEncoderLayer)\n",
    "\n",
    "Transformer operations are defined in \"Attention is all you need (2017).\" Differece between this and the Decoder layer is that the Encoder only attends to itself (Key/Value/Query is the source langage). Whereas in Decoder layer there is an attention over the memory (i.e., encoding of the input sequence) as well as the self-attention over the target sequence.\n",
    "\n",
    "**Input**: A 3D input of the structure [sequence length, batch size, hidden features].\n",
    "\n",
    "**Output**: Same structure as input.\n",
    "\n",
    "**Operation**: Key, Value, and Query are all the source sentence (only self-attention). See [source code](https://pytorch.org/docs/master/_modules/torch/nn/modules/transformer.html#TransformerEncoderLayer)\n",
    "\n",
    "```\n",
    "src2 = self.self_attn(src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask)[0]\n",
    "src = src + self.dropout1(src2)\n",
    "src = self.norm1(src)\n",
    "src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "src = src + self.dropout2(src2)\n",
    "src = self.norm2(src)\n",
    "return src\n",
    "```\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- **d_model** – the number of expected features in the input (required).\n",
    "- **nhead** – the number of heads in the multiheadattention models (required).\n",
    "- **dim_feedforward** – the dimension of the feedforward network model (default=2048).\n",
    "- **dropout** – the dropout value (default=0.1).\n",
    "- **activation** – the activation function of intermediate layer, relu or gelu (default=relu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([10, 32, 512])\n",
      "output shape: torch.Size([10, 32, 512])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(10, 32, 512)\n",
    "print(f'input shape: {x.shape}')\n",
    "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "y = encoder_layer(x)\n",
    "print(f'output shape: {y.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
